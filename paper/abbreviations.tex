\DeclareAcronym{HAWT}{
  short = HAWT ,
  long  = Horizontal Axis Wind Turbine ,
  class = abbrev
}
\DeclareAcronym{VAWT}{
  short = VAWT ,
  long  = Vertical Axis Wind Turbine ,
  class = abbrev
}
\DeclareAcronym{DDPG}{
  short = DDPG ,
  long  = Deep Deterministic Policy Gradients ,
  class = abbrev
}
\DeclareAcronym{DQN}{
  short = DQN ,
  long  = Deep Q-Networks ,
  class = abbrev
}
\DeclareAcronym{PG}{
  short = PG ,
  long  = Policy Gradients ,
  class = abbrev
}
\DeclareAcronym{DPG}{
  short = DPG ,
  long  = Deterministic Policy Gradients ,
  class = abbrev
}
\DeclareAcronym{TD3}{
  short = TD3 ,
  long  = Twin Delayed Deep Deterministic Policy Gradients ,
  class = abbrev
}
\DeclareAcronym{REINFORCE}{
  short = REINFORCE ,
  long  = REward Increment equals Nonnegative Factor x Offset Reinforcement x Characteristic Eligibility ,
  class = abbrev
}
\DeclareAcronym{RL}{
  short = RL ,
  long  = Reinforcement Learning ,
  class = abbrev
}
\DeclareAcronym{MDP}{
  short = MDP ,
  long  = Markov Decision Process ,
  class = abbrev
}
\DeclareAcronym{PER}{
  short = PER ,
  long  = Prioritized Experience Replay ,
  class = abbrev
}
\DeclareAcronym{FMM}{
  short = FMM ,
  long  = Forward Maniac Mode ,
  class = abbrev
}
\DeclareAcronym{BMM}{
  short = BMM ,
  long  = Backward Maniac Mode ,
  class = abbrev
}
\DeclareAcronym{RFC}{
  short = RFC ,
  long  = Rainflow Counting ,
  class = abbrev
}
\DeclareAcronym{DDDDPPG}{
  short = DDPG ,
  long  = Data-augmented Double Delayed Deep Deterministic Prioritized Policy Gradients ,
  class = abbrev
}
\DeclareAcronym{Off-PAC}{
  short = Off-PAC ,
  long = Off-Policy Actor Critic ,
  class = abbrev
}