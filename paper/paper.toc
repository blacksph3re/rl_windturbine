\contentsline {section}{\numberline {0.1}Background:}{2}{section.0.1}% 
\contentsline {section}{\numberline {0.2}Tasks}{2}{section.0.2}% 
\contentsline {chapter}{\numberline {1}Abstract}{4}{chapter.1}% 
\contentsline {chapter}{\numberline {2}Intro}{5}{chapter.2}% 
\contentsline {chapter}{\numberline {3}Background}{6}{chapter.3}% 
\contentsline {section}{\numberline {3.1}Windturbine control}{6}{section.3.1}% 
\contentsline {subsection}{\numberline {3.1.1}Why we do what we do}{8}{subsection.3.1.1}% 
\contentsline {section}{\numberline {3.2}QBlade}{9}{section.3.2}% 
\contentsline {section}{\numberline {3.3}Reinforcement learning}{11}{section.3.3}% 
\contentsline {subsection}{\numberline {3.3.1}Environment assumptions}{11}{subsection.3.3.1}% 
\contentsline {subsection}{\numberline {3.3.2}Definitions}{12}{subsection.3.3.2}% 
\contentsline {subsection}{\numberline {3.3.3}Q-Learning}{14}{subsection.3.3.3}% 
\contentsline {subsection}{\numberline {3.3.4}Policy Gradients}{15}{subsection.3.3.4}% 
\contentsline {subsection}{\numberline {3.3.5}Deterministic Policy Gradients}{18}{subsection.3.3.5}% 
\contentsline {subsection}{\numberline {3.3.6}DDPG}{19}{subsection.3.3.6}% 
\contentsline {section}{\numberline {3.4}RL on windturbines}{21}{section.3.4}% 
\contentsline {chapter}{\numberline {4}Experimentation}{24}{chapter.4}% 
\contentsline {section}{\numberline {4.1}Gym Experiments}{24}{section.4.1}% 
\contentsline {section}{\numberline {4.2}Starting with qblade}{24}{section.4.2}% 
\contentsline {section}{\numberline {4.3}Designing reward functions}{25}{section.4.3}% 
\contentsline {section}{\numberline {4.4}Aiding exploration}{26}{section.4.4}% 
\contentsline {subsection}{\numberline {4.4.1}Action Noise}{27}{subsection.4.4.1}% 
\contentsline {subsection}{\numberline {4.4.2}Random exploration}{27}{subsection.4.4.2}% 
\contentsline {subsection}{\numberline {4.4.3}Parameter noise}{28}{subsection.4.4.3}% 
\contentsline {section}{\numberline {4.5}Zero Gradients}{28}{section.4.5}% 
\contentsline {subsection}{\numberline {4.5.1}Simplifying the architecture}{28}{subsection.4.5.1}% 
\contentsline {subsection}{\numberline {4.5.2}Normalization}{29}{subsection.4.5.2}% 
\contentsline {section}{\numberline {4.6}High action gradients}{29}{section.4.6}% 
\contentsline {subsection}{\numberline {4.6.1}Gradient actionspace}{30}{subsection.4.6.1}% 
\contentsline {subsection}{\numberline {4.6.2}Feeding past timesteps}{30}{subsection.4.6.2}% 
\contentsline {subsection}{\numberline {4.6.3}Clipping action gradients}{30}{subsection.4.6.3}% 
\contentsline {subsection}{\numberline {4.6.4}Pretraining the policy}{31}{subsection.4.6.4}% 
\contentsline {section}{\numberline {4.7}Other improvements}{31}{section.4.7}% 
\contentsline {subsection}{\numberline {4.7.1}Prioritized experience replay}{31}{subsection.4.7.1}% 
\contentsline {subsection}{\numberline {4.7.2}Data augmentation}{33}{subsection.4.7.2}% 
\contentsline {section}{\numberline {4.8}Exploding Q-Loss}{34}{section.4.8}% 
\contentsline {subsection}{\numberline {4.8.1}Huber loss}{34}{subsection.4.8.1}% 
\contentsline {subsection}{\numberline {4.8.2}Double critic}{34}{subsection.4.8.2}% 
\contentsline {subsection}{\numberline {4.8.3}Batch normalization}{34}{subsection.4.8.3}% 
\contentsline {subsection}{\numberline {4.8.4}Regarding death conditions}{35}{subsection.4.8.4}% 
\contentsline {chapter}{\numberline {5}Algorithm}{36}{chapter.5}% 
\contentsline {section}{\numberline {5.1}QBlade}{36}{section.5.1}% 
\contentsline {section}{\numberline {5.2}Core algorithm}{37}{section.5.2}% 
\contentsline {chapter}{\numberline {6}Evaluation}{39}{chapter.6}% 
\contentsline {section}{\numberline {6.1}First working version}{39}{section.6.1}% 
\contentsline {section}{\numberline {6.2}HParam tuning}{39}{section.6.2}% 
\contentsline {section}{\numberline {6.3}Comparison to industry controllers}{40}{section.6.3}% 
\contentsline {chapter}{\numberline {7}Future work}{41}{chapter.7}% 
\contentsline {section}{\numberline {7.1}More computational power}{41}{section.7.1}% 
\contentsline {section}{\numberline {7.2}Train PID inputs}{41}{section.7.2}% 
\contentsline {section}{\numberline {7.3}Reward functions}{41}{section.7.3}% 
\contentsline {section}{\numberline {7.4}Switch reward functions during training}{41}{section.7.4}% 
\contentsline {section}{\numberline {7.5}Expert policy training}{42}{section.7.5}% 
\contentsline {section}{\numberline {7.6}Expert policy in instable conditions}{42}{section.7.6}% 
\contentsline {section}{\numberline {7.7}Active control elements}{42}{section.7.7}% 
\contentsline {chapter}{\numberline {8}Conclusion}{43}{chapter.8}% 
\contentsline {chapter}{\nonumberline Literaturverzeichnis}{44}{chapter*.7}% 
